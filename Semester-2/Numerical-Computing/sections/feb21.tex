\chapter*{Lecture 15 \\ February 21, Part B}
\addcontentsline{toc}{chapter}{Lecture 15 (February 21, Part B)}
\setcounter{chapter}{15}
\setcounter{section}{0}

\section{Newton's Method/Newton-Raphson Method}

Unlike the Bisection Method, here we don't have to evaluate $f$ to find the appropriate  $a$ and  $b$, which is a good thing. However, Newton's Method, as we will see, is not guaranteed to converge, which is a bad thing. We will also see that it depends crucially on the selection of $x_0$. Moreover, we will need the function to be differentiable in our domain of interest.

\subsection{Algorithm}
First, we make an estimate of the root $\alpha$ of $f$, which we shall denote by  $ x_0$.
Consider the equation of the line tangent to the graph of $y = f(x)$ at $(x_0, f(x_0))$
\[
p_1(x) = f(x_0) + f'(x_0)\left( x-x_0 \right)   
.\] 
This is just the linear Taylor polynomial for $f$ at  $ x_0$.

Define $ x_1$ to be the root of $ p_1(x) = 0$. We solve 
\[
p_1(x_1) = f(x_0) + f'(x_0)(x-x_0) = 0
.\] 
for $ x_1$ to get 
\[
x_1 = x_0 - \frac{f(x_0)}{f'(x_0)}
.\] 
Repeating this procedure, we get $ x_2$ from $ x_1$ as 
\[
x_2 = x_1 - \frac{f(x_1)}{f'(x_1)}
.\] 
Proceeding inductively, we get a sequence $\{x_n\}$ according to the following recusion formula:
\begin{equation}\label{eq1:feb21B}
	 x_{n+1} = x_n - \frac{f(x_n)}{f'(x_{n+1})}, n \geq 0
\end{equation}
The sequence $\{x_n\}$ is a sequence of estimates for  $\alpha$. This procedure of estimating the root $\alpha$ using the recursion formula $\left( \ref{eq1:feb21B} \right) $ is known as the \textbf{Newton-Raphson Method}.
\newpage

\subsection{An example computation problem}

	Now, we take a look at an example computation problem that can be solved using the Newton-Raphson Method.

	Given $a,b \in \N$, we want to compute $\frac{a}{b}$ without performing the division operation.
	
	Early computers could support addition, subtraction and multiplication but division needed to be implemented using an algorithm as we are going to discuss.
	In order to solve this problem, we take the inputs $a,b$, following which we can get the answer by multiplying  $a$ and  $\frac{1}{b}$. For this, we need to compute $\frac{1}{b}$, which can be done by solving 
\begin{equation}\label{eq2:feb21B}
	f(x) = b - \frac{1}{x} = 0 
\end{equation}
Remember that here we are trying to estimate the root $\alpha = \frac{1}{b}$ of the function $f$ defined in $\left( \ref{eq2:feb21B}\right) $ . 
	We have $f'(x) = \frac{1}{x^2}$. So, by the Newton's Method, the recursion that we get is 
	\[
		x_{n+1} = x_n - \frac{b-\frac{1}{x_n}}{\frac{1}{x_n^2}}
	.\] 
	which on simplifying gives us
	\begin{equation}\label{eq3:feb21B}
		x_{n+1} = x_n\left( 2-bx_n \right), n \geq 0 
	\end{equation}
	Notice that the arithmetic of $\left( \ref{eq3:feb21B} \right) $ involves only subtraction and multiplication which were supported in the early computers.

	Now, we look at the error analysis of this procedure.
	From $\epsilon_{x_n} = \frac{\alpha-x_n}{\alpha}$, we easily get
	\begin{equation}\label{eq4:feb21B}
	 \epsilon_{x_{n+1}} = \epsilon_{x_n}^2 \implies \epsilon_{x_n} = \left( \epsilon_{x_0} \right)^{2^n} 
 \end{equation}
 According to $\left( \ref{eq4:feb21B} \right) $, the relative error of $x_n$,i.e. $\epsilon_{x_n}$, can rapidly decrease to $0$, as $n$ increases if we can ensure $|\epsilon_{x_0}| < 1$.

	So, we want $|\frac{\alpha - x_0}{\alpha}| < 1$.
	\begin{itemize}
		\item If $x_0 > \alpha$, then  $\frac{x_0-\alpha}{\alpha} < 1 \implies x_0 < 2\alpha = \frac{2}{b}$\\
		\item If $ x_0 < \alpha$, then $\frac{\alpha - x_0}{\alpha} < 1 \implies x_0 > 0$
	\end{itemize}
	This gives us the equivalent condition $0 < x_0 < \frac{2}{b}$ 
	Therefore, the Newton-Raphson Method guarantees convergence to $\alpha = \frac{1}{b}$ if and only if $x_0$ satisfies the above condition.

	At the lowest levels, this procedure is how computation is carried out by some computers even today.
