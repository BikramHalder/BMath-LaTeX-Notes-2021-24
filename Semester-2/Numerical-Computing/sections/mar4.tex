\chapter*{Lecture 18 \\ March 4}
\addcontentsline{toc}{chapter}{Lecture 18 (March 4)}
\setcounter{chapter}{18}
\setcounter{section}{0}

\section{Fixed point methods}

Instead of trying to find a root to an equation of the form $f(x) = 0$, we can try to find a root to an equation of the form $x - f(x) = x$. Defining $g(x) \coloneqq x - f(x)$, we see that the task of finding a root of $f$ is equivalent to finding a \textbf{fixed point} of $g$ (a fixed point of a function $g$ is a real $\alpha$ such that $g(\alpha) = \alpha$).

We shall deal mainly with non-linear functions, as finding the roots/fixed points of linear functions can be done by employing the techniques of linear algebra, which we have already covered.

Therefore, we now set for ourselves the task of finding fixed points $\alpha$ of a function $g$. But first, we recall some theorems that we proved in previous lectures

\begin{thm}
  \label{mar4:thm:efp}
  \hfill
  
  If the following conditions obtain,
  \begin{itemize}
  \item
    $g \colon [a, b] \to [a, b]$.
    
  \item
    $g$ is continuous on $[a, b]$.
    
  \end{itemize}
  then $g$ has a (not necessarily unique) fixed point in $[a, b]$.
  \hfill\qed
\end{thm}

\begin{thm}
  \label{mar4:thm:ufp}
  \hfill
  
  If the following conditions obtain,
  \begin{itemize}
  \item
    $g \colon [a, b] \to [a, b]$.

  \item
    $g$ is continuous on $[a, b]$.

  \item
    $g'$ exists in $[a, b]$.

  \item
    $g'$ is continuous on $[a, b]$.

  \item
    $\lambda \coloneqq \max_{x \in [a, b]} \abs{g'(x)} < 1$.

  \end{itemize}
  then $g$ has a \textbf{unique} fixed point in $[a, b]$.
  \hfill\qed
\end{thm}
Note that we have the same problem here as when we did the bisection method; the problem of finding a suitable interval ($[a, b]$ in this case). But let us assume that you have found such an interval, and proceed.

Under the assumptions of theorem \ref{mar4:thm:ufp}, if we start with an initial guess $x_0 \in [a, b]$, and define subsequent guesses using the recursion
\begin{defn}
  \label{mar4:def:iter}
  \[
    x_{n+1} = g(x_n) \qquad \forall(n \geq 0)
  \]
\end{defn}
then if we denote the unique fixed point of $g$ in $[a, b]$ by $\alpha$, we have
\begin{thm}
  \label{mar4:thm:2c}
  \[
    \abs{\alpha - x_n} \leq \lambda^n\abs{\alpha - x_0}
  \]
\end{thm}

\begin{proof}
  Assuming the preconditions of theorem \ref{mar4:thm:ufp}, $g \colon [a, b] \to [a, b]$. Combining that with the fact that $x_0 \in [a, b]$, it is easy to see by induction that $x_n \in [a, b]$ for all $n \geq 0$.

  Now, by definition \ref{mar4:def:iter}, and the fact that $g(\alpha) = \alpha$, we have
  \[
    \alpha - x_{n+1} = g(\alpha) - g(x_n) = g'(c_n)(\alpha - x_n)
  \]
  for some $c_n \in (\alpha, x_n)$, by the \emph{mean value theorem}. Since by the preconditions of theorem \ref{mar4:thm:ufp} $\lambda \coloneqq \max_{x \in [a, b]} \abs{g'(x)} < 1$, we obtain from the above equation
  \[
    \abs{\alpha - x_{n+1}} \leq \lambda\abs{\alpha - x_n}
  \]
  By induction, we get
  \[
    \abs{\alpha - x_n} \leq \lambda^n\abs{\alpha - x_0}
  \]
  \hfill
\end{proof}
\begin{corr}
  Under the assumptions of theorem \ref{mar4:thm:ufp},
  \[
    \lim_{n\to\infty} x_n = \alpha
  \]
\end{corr}
\begin{proof}
  By theorem \ref{mar4:thm:2c}, $\abs{\alpha - x_n} \leq \lambda^n\abs{\alpha - x_0}$. Since $\lambda < 1$, we get
  \[
    \lim_{n\to\infty}\abs{\alpha - x_n} = 0
  \]
  using the squeeze theorem (the L.H.S. of the squeeze is $0 \leq \abs{\alpha - x_n}$, which follows from properties of the $\abs{\cdot}$ function).
  \hfill
\end{proof}
\begin{corr}
  Under the assumptions of theorem \ref{mar4:thm:ufp},
  \[
    \abs{\alpha - x_n} \leq \frac{\lambda^n}{1 - \lambda}\abs{x_0 - x_1}
  \]
\end{corr}
\begin{proof}
  Note that
  \begin{align*}
    &\abs{\alpha - x_0}
      \lao[\leq]{1} \abs{\alpha - x_1} + \abs{x_0 - x_1}
      \lao[\leq]{2} \lambda\abs{\alpha - x_0} + \abs{x_0 - x_1} \\\\
    \implies&
              (1-\lambda)\abs{\alpha - x_0}
              \leq
              \abs{x_0 - x_1} \\\\
    \lao[\implies]{3}&
              \abs{\alpha - x_0}
              \leq
              \frac{\abs{x_0 - x_1}}{1-\lambda} \tag{4}
  \end{align*}
  where inequality (1) is the triangle inequality, and inequality 2 follows from theorem \ref{mar4:thm:2c}. Implication (3) is justified as $\lambda < 1$ and therefore we are not dividing by 0. But then
  \[
    \abs{\alpha - x_n}
    \lao[\leq]{5}
    \lambda^n\abs{\alpha - x_0}
    \lao[\leq]{6}
    \frac{\lambda^n}{1-\lambda}\abs{x_0 - x_1}
  \]
  where inequality (5) follows from theorem \ref{mar4:thm:2c}, and inequality (6) follows from inequality (4) above.
  
  \hfill
\end{proof}
Now we come to what is probably the most important theorem in this lecture.
\begin{thm}
  Under the assumptions of theorem \ref{mar4:thm:ufp},
  \label{mar4:thm:bigtp}
  \[
    \lim_{n\to\infty} \frac{\alpha - x_{n+1}}{\alpha - x_n} = g'(\alpha)
  \]
\end{thm}
\begin{proof}
  Note that by the mean value theorem, for all $n \geq 0$ we have $\alpha - x_{n+1} = g(\alpha) - g(x_n) = g'(c_n)(\alpha - x_n)$ for some $c_n \in (\alpha, x_n)$. Therefore,
  \[
    \lim_{n\to\infty} \frac{\alpha - x_{n+1}}{\alpha - x_n} = \lim_{n\to\infty} g'(c_n)
  \]
  But since $x_n \to \alpha$, $c_n \to \alpha$ too, and then using the fact that $g'$ is continuous in $[a, b]$, we get
  \[
    \lim_{n\to\infty} g'(c_n) = g'(\alpha)
  \]
  \hfill
\end{proof}

\begin{defn}
  Suppose we have a sequence $\{y_n \}$ that converges to $\beta$. We say that $\{y_n \}$ converges to $\beta$ \textbf{linearly}, if for all $n$
  \[
    \beta - y_{n+1} \approx c(\beta - y_n)^p
  \]
  with $p = 1$.

  If $p > 1$, we say that the sequence $\{y_n \}$ converges to $\beta$ \textbf{super-linearly}.
\end{defn}
We are now ready to state the final theorem of this lecture.
\begin{thm}
  If we assume the preconditions of \ref{mar4:thm:ufp}, and we additionally assume that $g'(\alpha) \neq 0$, $x_n$ converges to $\alpha$ linearly.
\end{thm}
\begin{proof}
  Theorem \ref{mar4:thm:bigtp} tells us that $\lim_{n\to\infty} \frac{\alpha - x_{n+1}}{\alpha - x_n} = g'(\alpha)$. That implies, as long as $g'(\alpha) \neq 0$ and therefore higher order terms do not dominate, that for large $n$,
  \[
    \alpha - x_{n+1} \approx g'(\alpha)(\alpha - x_n)
  \]
  (The convergence is guaranteed both by theorem \ref{mar4:thm:efp} and by the fact that $g'(\alpha) < 1$, which follows from the preconditions of \ref{mar4:thm:ufp}).
\hfill
\end{proof}

We end by remarking that fixed point iterations are very easy to program owing to the simple nature of their iterations.

[Stopped at 37:36 $\pm$ a few seconds. The remainder of the lecture is about polynomial interpolation.]

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../NC"
%%% End:
